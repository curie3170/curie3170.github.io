<!DOCTYPE html>
<html>

    <head>
        <meta charset="utf-8">
        <meta content="width=device-width, initial-scale=1" name="viewport">
        <link rel="stylesheet" href="/gradfolio/assets/css/main.css">

        <h1 class="post-headline">Curie Kim</h1>
        <h3 class="post-description">Computer Vision Researcher | Gwangju Institute of Science and Technology |</h3>

        <div class="links scroll">
        <a href="/gradfolio/">Home</a>
        <a href="/gradfolio/projects/">Projects</a>
        <a href="/gradfolio/blog/">Blog</a>
        <a href="/gradfolio/archive/">Archive</a>
</div>


        <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>3D Object Detection (2020) | Curie Kim</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="3D Object Detection (2020)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Move to project summary" />
<meta property="og:description" content="Move to project summary" />
<link rel="canonical" href="http://localhost:4000/gradfolio/projects/2/" />
<meta property="og:url" content="http://localhost:4000/gradfolio/projects/2/" />
<meta property="og:site_name" content="Curie Kim" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-04T03:50:22+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="3D Object Detection (2020)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-04T03:50:22+09:00","datePublished":"2022-10-04T03:50:22+09:00","description":"Move to project summary","headline":"3D Object Detection (2020)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/gradfolio/projects/2/"},"url":"http://localhost:4000/gradfolio/projects/2/"}</script>
<!-- End Jekyll SEO tag -->


        <!-- Generated using https://favicon.io/ -->
<link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png?">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png?">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png?">
<link rel="manifest" href=site.webmanifest">


        <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
     processEscapes: true
    }
  });
</script>


        <!-- Load fontawesome here for faster loadtimes: https://stackoverflow.com/a/35880730/9523246 -->
        <script type="text/javascript"> (function() { var css = document.createElement('link'); css.href = 'https://use.fontawesome.com/releases/v5.11.0/css/all.css'; css.rel = 'stylesheet'; css.type = 'text/css'; document.getElementsByTagName('head')[0].appendChild(css); })(); </script>
    </head>

    <body>
        <main>
            <article>
                <h1 class="post-headline">3D Object Detection (2020)</h1>
<p class="meta"><small>October 04, 2022</small></p>

<h1 id="self-supervised-3d-object-detection-from-monocular-pseudo-lidar-curie-kim-ue-hwan-kim-and-jong-hwan-kim">Self-supervised 3D Object Detection from Monocular Pseudo-LiDAR, Curie Kim, Ue-Hwan Kim, and Jong-Hwan Kim</h1>
<ul>
  <li>Published in <em>The 2022 IEEE International Conference on Multisensor Fusion and Integration</em>
</li>
  <li>Github Repo is <a href="https://github.com/curie3170/Mono3d" target="_blank" rel="noopener noreferrer">here</a>.</li>
  <li>arXiv link is <a href="https://arxiv.org/abs/2209.09486" target="_blank" rel="noopener noreferrer">here</a>.</li>
</ul>

<h1 id="network-architecture">Network Architecture</h1>
<p><img src="https://user-images.githubusercontent.com/17980462/177569344-01ceb000-7bd2-42d8-bf40-18e4de48b850.png" alt="example image"></p>

<p>Our 3D object detection network. Three sequential images, It−1, It, It+1 are used as inputs to estimate the camera pose, while the depth network feeds only It. Learning with supervised loss (D) or self-supervised loss (M) or both (MD) are available, and the predicted depth is converted into a pseudo-LiDAR from through a change of representation scheme proposed by [3]. Then the 3D object network detects 3D objects by considering it as a LiDAR sensor measurement result.</p>

<h1 id="abstract">Abstract</h1>
<p>There have been attempts to detect 3D objects by fusion of stereo camera images and LiDAR sensor data or using LiDAR for pre-training and only monocular images for testing, but there have been less attempts to use only monocular image sequences due to low accuracy. In addition, when depth prediction using only monocular images, only scale-inconsistent depth can be predicted, which is the reason why researchers are reluctant to use monocular images alone. Therefore, we propose a method for predicting absolute depth and detecting 3D objects using only monocular image sequences by enabling end-to-end learning of detection networks and depth prediction networks. As a result, the proposed method surpasses other existing methods in performance on the KITTI 3D dataset. Even when monocular image and 3D LiDAR are used together during training in an attempt to improve performance, ours exhibit is the best performance compared to other methods using the same input. In addition, end-to-end learning not only improves
depth prediction performance, but also enables absolute depth prediction, because our network utilizes the fact that the size of a 3D object such as a car is determined by the approximate size.</p>

<h1 id="depth-scaled-loss">Depth Scaled Loss</h1>

<p>Due to the inherent scale ambiguity of monocular depth estimation, the process of monocular 3D object detection could become unstable. To deal with this, we propose a scaleaware depth estimation method. The key to overcoming the scale ambiguity is to represent depths as follows:
 \(\hat{d} = \frac{\bar{D}_{\text{prior}}}{\sigma_\text{min} + (\sigma_\text{max} - \sigma_\text{min}) \cdot x}\)</p>

<h1 id="depth-estimation-results">Depth Estimation Results</h1>
<p><img src="https://user-images.githubusercontent.com/17980462/193173420-4684c338-cea2-41ac-9d50-b78f9481d26d.png" alt="example image"></p>

<h1 id="3d-object-detection-results">3D Object Detection Results</h1>
<p><img src="https://user-images.githubusercontent.com/17980462/177567814-3d6d8e33-0f80-4c3f-bf7d-8ea2cb1e4fa7.png" alt="example image">
<img src="https://user-images.githubusercontent.com/17980462/193173628-5a4375b6-9dbe-4e76-b340-e5753f2c289c.png" alt="example image"></p>



<!-- Comments only for posts -->


            </article>
        </main>

        <footer>
          <p class="copy">
            <small> © Curie Kim 2022
                    | Powered by Jekyll and
                    <a target="_blank" href="https://github.com/jitinnair1/gradfolio/" rel="noopener noreferrer">Gradfolio</a>.
                    Last updated on 04 October 2022
            </small>
          </p>

        <div class="rounded-social-buttons">
<a title="" class="social-button linkedin" href="https://www.linkedin.com/in/https://www.linkedin.com/in/curie-kim-219a78190/" itemprop="sameAs" target="_blank" rel="noopener noreferrer">
<i class="fab fa-linkedin"></i>
</a><a title="" class="social-button github" href="https://www.github.com/https://github.com/curie3170" itemprop="sameAs" target="_blank" rel="noopener noreferrer">
<i class="fab fa-github"></i>
</a><a title="" class="social-button google" itemprop="sameAs" href="https://scholar.google.com/https://scholar.google.com/citations?user=DN1ps7wAAAAJ" target="_blank" rel="noopener noreferrer">
<i class="fa fa-graduation-cap"></i>
</a>
</div>


        </footer>

        <!-- Google Analytics Tracking code -->
<script src="https://cdn.jsdelivr.net/npm/ga-lite@1/dist/ga-lite.min.js" async></script>
<script>
var galite = galite || {};
galite.UA = '';
</script>

    </body>

</html>
